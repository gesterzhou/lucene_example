diff --git a/geode-assembly/build.gradle b/geode-assembly/build.gradle
index 19a73f324..b39f7e6df 100755
--- a/geode-assembly/build.gradle
+++ b/geode-assembly/build.gradle
@@ -194,6 +194,8 @@ def cp = {
         it.contains('lucene-analyzers-common') ||
         it.contains('lucene-core') ||
         it.contains('lucene-queries') ||
+        it.contains('lucene-join') ||
+        it.contains('lucene-grouping') ||
         it.contains('lucene-queryparser') ||
 
         // dependencies from geode-protobuf
diff --git a/geode-assembly/src/test/resources/expected_jars.txt b/geode-assembly/src/test/resources/expected_jars.txt
index 05f583459..fc18ab4ad 100644
--- a/geode-assembly/src/test/resources/expected_jars.txt
+++ b/geode-assembly/src/test/resources/expected_jars.txt
@@ -46,6 +46,8 @@ lucene-analyzers-common
 lucene-core
 lucene-queries
 lucene-queryparser
+lucene-join
+lucene-grouping
 mx4j
 mx4j-remote
 mx4j-tools
diff --git a/geode-lucene/build.gradle b/geode-lucene/build.gradle
index 74de7a6a8..360ab55fb 100644
--- a/geode-lucene/build.gradle
+++ b/geode-lucene/build.gradle
@@ -22,6 +22,8 @@ dependencies {
     compile 'org.apache.lucene:lucene-analyzers-common:' + project.'lucene.version'
     compile 'org.apache.lucene:lucene-core:' + project.'lucene.version'
     compile 'org.apache.lucene:lucene-queries:' + project.'lucene.version'
+    compile 'org.apache.lucene:lucene-join:' + project.'lucene.version'
+    compile 'org.apache.lucene:lucene-grouping:' + project.'lucene.version'
     compile ('org.apache.lucene:lucene-queryparser:' + project.'lucene.version') {
       exclude module: 'lucene-sandbox'
     }
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/AbstractPartitionedRepositoryManager.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/AbstractPartitionedRepositoryManager.java
index 867794d05..67d860f06 100755
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/AbstractPartitionedRepositoryManager.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/AbstractPartitionedRepositoryManager.java
@@ -128,7 +128,7 @@ public abstract class AbstractPartitionedRepositoryManager implements Repository
   /**
    * Return the repository for a given user bucket
    */
-  protected IndexRepository getRepository(Integer bucketId) throws BucketNotFoundException {
+  public IndexRepository getRepository(Integer bucketId) throws BucketNotFoundException {
     IndexRepository repo = indexRepositories.get(bucketId);
     if (repo != null && !repo.isClosed()) {
       return repo;
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/RawLuceneRepositoryManager.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/RawLuceneRepositoryManager.java
index b9f4de898..59d076e0e 100755
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/RawLuceneRepositoryManager.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/RawLuceneRepositoryManager.java
@@ -29,7 +29,7 @@ public class RawLuceneRepositoryManager extends AbstractPartitionedRepositoryMan
   }
 
   @Override
-  protected IndexRepository getRepository(Integer bucketId) throws BucketNotFoundException {
+  public IndexRepository getRepository(Integer bucketId) throws BucketNotFoundException {
     IndexRepository repo = indexRepositories.get(bucketId);
     if (repo != null && !repo.isClosed()) {
       return repo;
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/IndexRepositoryImpl.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/IndexRepositoryImpl.java
index f356bef6b..597473aed 100644
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/IndexRepositoryImpl.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/IndexRepositoryImpl.java
@@ -15,6 +15,7 @@
 
 package org.apache.geode.cache.lucene.internal.repository;
 
+import org.apache.commons.beanutils.PropertyUtils;
 import org.apache.geode.cache.Region;
 import org.apache.geode.cache.lucene.internal.LuceneIndexStats;
 import org.apache.geode.cache.lucene.internal.repository.serializer.LuceneSerializer;
@@ -33,7 +34,10 @@ import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.geode.distributed.LockNotHeldException;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.function.IntSupplier;
+import java.lang.reflect.Field;
+import java.lang.reflect.InvocationTargetException;
 
 /**
  * A repository that writes to a single lucene index writer
@@ -95,10 +99,22 @@ public class IndexRepositoryImpl implements IndexRepository {
   public void update(Object key, Object value) throws IOException {
     long start = stats.startUpdate();
     try {
-      Document doc = new Document();
-      SerializerUtil.addKey(key, doc);
-      serializer.toDocument(value, doc);
-      writer.updateDocument(SerializerUtil.getKeyTerm(doc), doc);
+//      Document doc = new Document();
+//      SerializerUtil.addKey(key, doc);
+//      serializer.toDocument(value, doc);
+//      writer.updateDocument(SerializerUtil.getKeyTerm(doc), doc);
+      ArrayList<Document> documents = (ArrayList<Document>)serializer.toDocuments(value);
+      if (documents == null) {
+        // PDX
+        return;
+      }
+      for (Document doc:documents) {
+        SerializerUtil.addKey(key, doc);
+      }
+      Document lastDoc = documents.get(documents.size()-1);
+//      SerializerUtil.addKey(key, lastDoc);
+//      System.out.println("GGG:"+documents);
+      writer.updateDocuments(SerializerUtil.getKeyTerm(lastDoc), documents);
     } finally {
       stats.endUpdate(start);
     }
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/HeterogeneousLuceneSerializer.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/HeterogeneousLuceneSerializer.java
index b0a98a1e8..889e3f7c2 100644
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/HeterogeneousLuceneSerializer.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/HeterogeneousLuceneSerializer.java
@@ -14,8 +14,14 @@
  */
 package org.apache.geode.cache.lucene.internal.repository.serializer;
 
+import java.lang.reflect.Field;
+import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
 import java.util.Map;
+import java.util.Set;
 
 import org.apache.logging.log4j.Logger;
 import org.apache.lucene.document.Document;
@@ -46,7 +52,7 @@ public class HeterogeneousLuceneSerializer implements LuceneSerializer {
    * 
    * Weak so that entry will be removed if a class is garbage collected.
    */
-  private Map<Class<?>, LuceneSerializer> mappers =
+  public Map<Class<?>, LuceneSerializer> mappers =
       new CopyOnWriteWeakHashMap<Class<?>, LuceneSerializer>();
 
   private static final Logger logger = LogService.getLogger();
@@ -86,22 +92,103 @@ public class HeterogeneousLuceneSerializer implements LuceneSerializer {
     }
   }
 
+  public HashMap<Class<?>, HashSet<String>> definedFieldsForEachNestedClass = new HashMap();
+
+  private void preProcessingForNestObjects(Object value, String[] fields) {
+    Class<?> clazz = value.getClass();
+    HashSet<String> definedFieldNamesForParent = definedFieldsForEachNestedClass.get(clazz);
+    if (definedFieldNamesForParent == null) {
+      definedFieldNamesForParent = new HashSet<String>();
+      definedFieldsForEachNestedClass.put(clazz, definedFieldNamesForParent);
+    }
+
+    HashMap<String, HashSet<String>> parentChildFieldMapping =  new HashMap();
+    for (String f:fields) {
+      int firstDot = f.indexOf(".");
+      if (firstDot != -1) {
+        String parentFieldName = f.substring(0, firstDot);
+        String childFieldName = f.substring(firstDot+1);
+        HashSet<String> childFieldSet = parentChildFieldMapping.get(parentFieldName);
+        if (childFieldSet == null) {
+          childFieldSet = new HashSet<String>();
+          parentChildFieldMapping.put(parentFieldName, childFieldSet);
+        }
+        childFieldSet.add(childFieldName);
+
+        definedFieldNamesForParent.add(parentFieldName);
+      } else {
+        definedFieldNamesForParent.add(f);
+      }
+    }
+
+    for (Map.Entry<String, HashSet<String>> entry:parentChildFieldMapping.entrySet()) {
+      try {
+        String parentFieldName = entry.getKey();
+        HashSet<String> childFieldSet = entry.getValue();
+        String[] childFields = new String[childFieldSet.size()];
+        childFieldSet.toArray(childFields);
+        checkOneNestedField(value, parentFieldName, childFields);
+      }
+      catch (Exception e) {
+        e.printStackTrace();
+      }
+    }
+  }
+
+  private void checkOneNestedField(Object parentValue, String parentField, String[] childFields) throws IllegalArgumentException, IllegalAccessException, NoSuchFieldException, SecurityException {
+    // now check if there's grandchild in nestedFields
+    Class<?> parentClazz = parentValue.getClass();
+    Field field = parentClazz.getDeclaredField(parentField);
+    Object childValue = null;
+    try {
+      field.setAccessible(true);
+      childValue = field.get(parentValue);
+    } catch (Exception e) {
+      e.printStackTrace(System.out);
+    }
+    preProcessingForNestObjects(childValue, childFields);
+  }
+
   /**
    * Get the field mapper based on the type of the given object.
    */
-  private LuceneSerializer getFieldMapper(Object value) {
+  public LuceneSerializer getFieldMapper(Object value) {
     if (value instanceof PdxInstance) {
       return pdxMapper;
     } else {
-      Class<?> clazz = value.getClass();
-      LuceneSerializer mapper = mappers.get(clazz);
+//      Class<?> clazz = value.getClass();
+      LuceneSerializer mapper = mappers.get(value.getClass());
       if (mapper == null) {
-        mapper = new ReflectionLuceneSerializer(clazz, indexedFields);
-        mappers.put(clazz, mapper);
+        // only do pre-processing when mapper==null
+        // it will find all the nested classes for the index
+        preProcessingForNestObjects(value, indexedFields);
+        for (Map.Entry<Class<?>, HashSet<String>> entry:definedFieldsForEachNestedClass.entrySet()) {
+          Class<?> clazz = entry.getKey();
+          if (mappers.get(clazz) == null) {
+            HashSet<String> childFieldSet = entry.getValue();
+            String[] fields = entry.getValue().toArray(new String[childFieldSet.size()]);
+            mapper = new ReflectionLuceneSerializer(clazz, fields, this);
+            mappers.put(clazz, mapper);
+          }
+        }
       }
-      return mapper;
+
+      return mappers.get(value.getClass());
     }
   }
 
+  @Override
+  public Collection<Document> toDocuments(Object value) {
+    if (value == null) {
+      return null;
+    }
 
+    LuceneSerializer mapper = getFieldMapper(value);
+
+    Collection<Document> docs = mapper.toDocuments(value);
+    if (logger.isDebugEnabled()) {
+      logger.debug("HeterogeneousLuceneSerializer.toDocuments:" + docs);
+    }
+    return docs;
+  }
 }
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/LuceneSerializer.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/LuceneSerializer.java
index fa38f4730..1c929783d 100644
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/LuceneSerializer.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/LuceneSerializer.java
@@ -15,6 +15,8 @@
 
 package org.apache.geode.cache.lucene.internal.repository.serializer;
 
+import java.util.Collection;
+
 import org.apache.lucene.document.Document;
 
 /**
@@ -27,4 +29,6 @@ public interface LuceneSerializer {
    */
   void toDocument(Object value, Document doc);
 
+  //Proposed method
+  Collection<Document> toDocuments(Object value);
 }
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PdxLuceneSerializer.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PdxLuceneSerializer.java
index f34390c65..994f00c25 100644
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PdxLuceneSerializer.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PdxLuceneSerializer.java
@@ -18,6 +18,7 @@ package org.apache.geode.cache.lucene.internal.repository.serializer;
 import org.apache.logging.log4j.Logger;
 import org.apache.lucene.document.Document;
 
+import java.util.Collection;
 import org.apache.geode.internal.logging.LogService;
 import org.apache.geode.pdx.PdxInstance;
 
@@ -50,4 +51,10 @@ class PdxLuceneSerializer implements LuceneSerializer {
       logger.debug("PdxLuceneSerializer.toDocument:" + doc);
     }
   }
+
+  @Override
+  public Collection<Document> toDocuments(Object value) {
+    // TODO Auto-generated method stub
+    return null;
+  }
 }
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PrimitiveSerializer.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PrimitiveSerializer.java
index cf644a8bc..a47c69624 100644
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PrimitiveSerializer.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PrimitiveSerializer.java
@@ -14,6 +14,7 @@
  */
 package org.apache.geode.cache.lucene.internal.repository.serializer;
 
+import java.util.Collection;
 import org.apache.geode.cache.lucene.LuceneService;
 
 import org.apache.lucene.document.Document;
@@ -28,4 +29,10 @@ public class PrimitiveSerializer implements LuceneSerializer {
   public void toDocument(final Object value, final Document doc) {
     SerializerUtil.addField(doc, LuceneService.REGION_VALUE_FIELD, value);
   }
+
+  @Override
+  public Collection<Document> toDocuments(Object value) {
+    // TODO Auto-generated method stub
+    return null;
+  }
 }
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionLuceneSerializer.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionLuceneSerializer.java
index 07a66fb0a..5ab95a371 100644
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionLuceneSerializer.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionLuceneSerializer.java
@@ -18,7 +18,10 @@ package org.apache.geode.cache.lucene.internal.repository.serializer;
 import java.lang.reflect.Field;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collection;
+import java.util.HashMap;
 import java.util.HashSet;
+import java.util.Map;
 import java.util.Set;
 
 import org.apache.logging.log4j.Logger;
@@ -33,10 +36,12 @@ import org.apache.geode.internal.logging.LogService;
 class ReflectionLuceneSerializer implements LuceneSerializer {
 
   private Field[] fields;
+  HeterogeneousLuceneSerializer hSerializer;
 
   private static final Logger logger = LogService.getLogger();
 
-  public ReflectionLuceneSerializer(Class<? extends Object> clazz, String[] indexedFields) {
+  public ReflectionLuceneSerializer(Class<? extends Object> clazz, String[] indexedFields, HeterogeneousLuceneSerializer hSerializer) {
+    this.hSerializer = hSerializer;
     Set<String> fieldSet = new HashSet<String>();
     fieldSet.addAll(Arrays.asList(indexedFields));
 
@@ -47,7 +52,7 @@ class ReflectionLuceneSerializer implements LuceneSerializer {
     while (clazz != Object.class) {
       for (Field field : clazz.getDeclaredFields()) {
         Class<?> type = field.getType();
-        if (fieldSet.contains(field.getName()) && SerializerUtil.isSupported(type)) {
+        if (fieldSet.contains(field.getName())) {
           field.setAccessible(true);
           foundFields.add(field);
         }
@@ -57,6 +62,7 @@ class ReflectionLuceneSerializer implements LuceneSerializer {
     }
 
     this.fields = foundFields.toArray(new Field[foundFields.size()]);
+    this.hSerializer = hSerializer;
   }
 
   @Override
@@ -76,4 +82,39 @@ class ReflectionLuceneSerializer implements LuceneSerializer {
       logger.debug("ReflectionLuceneSerializer.toDocument:" + doc);
     }
   }
+
+  @Override
+  public Collection<Document> toDocuments(Object value) {
+    ArrayList<Document> docs = new ArrayList();
+    Document parentDoc = new Document();
+    boolean isParentDocEmpty = true;
+
+    for (Field field : fields) {
+      try {
+        field.setAccessible(true);
+        Object fieldValue = field.get(value);
+        Class<?> fieldType = field.getType();
+        if (fieldValue == null) {
+          continue;
+        }
+
+        if (hSerializer.definedFieldsForEachNestedClass.containsKey(fieldType)) {
+          LuceneSerializer childSerializer = hSerializer.getFieldMapper(fieldValue);
+          docs.addAll(childSerializer.toDocuments(fieldValue));
+        } else {
+          SerializerUtil.addField(parentDoc, field.getName(), fieldValue);
+          isParentDocEmpty = false;
+        }
+      } catch (IllegalArgumentException | IllegalAccessException e) {
+        // TODO - what to do if we can't read a field?
+      }
+    }
+    if (logger.isDebugEnabled()) {
+      logger.debug("ReflectionLuceneSerializer.toDocuments:" + docs);
+    }
+    if (!isParentDocEmpty) {
+      docs.add(parentDoc);
+    }
+    return docs;
+  }
 }
diff --git a/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionFieldMapperJUnitTest.java b/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionFieldMapperJUnitTest.java
index 3e0fe3ff8..e7aad0c5d 100644
--- a/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionFieldMapperJUnitTest.java
+++ b/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionFieldMapperJUnitTest.java
@@ -32,8 +32,8 @@ public class ReflectionFieldMapperJUnitTest {
   public void testAllFields() {
 
     String[] allFields = new String[] {"s", "i", "l", "d", "f", "s2"};
-    ReflectionLuceneSerializer mapper1 = new ReflectionLuceneSerializer(Type1.class, allFields);
-    ReflectionLuceneSerializer mapper2 = new ReflectionLuceneSerializer(Type2.class, allFields);
+    ReflectionLuceneSerializer mapper1 = new ReflectionLuceneSerializer(Type1.class, allFields, null);
+    ReflectionLuceneSerializer mapper2 = new ReflectionLuceneSerializer(Type2.class, allFields, null);
 
     Type1 t1 = new Type1("a", 1, 2L, 3.0, 4.0f);
     Type2 t2 = new Type2("a", 1, 2L, 3.0, 4.0f, "b");
@@ -64,7 +64,7 @@ public class ReflectionFieldMapperJUnitTest {
   public void testIgnoreInvalid() {
 
     String[] fields = new String[] {"s", "o", "s2"};
-    ReflectionLuceneSerializer mapper = new ReflectionLuceneSerializer(Type2.class, fields);
+    ReflectionLuceneSerializer mapper = new ReflectionLuceneSerializer(Type2.class, fields, null);
 
     Type2 t = new Type2("a", 1, 2L, 3.0, 4.0f, "b");
 
@@ -80,7 +80,7 @@ public class ReflectionFieldMapperJUnitTest {
   public void testNullField() {
 
     String[] fields = new String[] {"s", "o", "s2"};
-    ReflectionLuceneSerializer mapper = new ReflectionLuceneSerializer(Type2.class, fields);
+    ReflectionLuceneSerializer mapper = new ReflectionLuceneSerializer(Type2.class, fields, null);
 
     Type2 t = new Type2("a", 1, 2L, 3.0, 4.0f, null);
 
diff --git a/geode-web-api/build.gradle b/geode-web-api/build.gradle
index 795812fba..bcf1e0e36 100755
--- a/geode-web-api/build.gradle
+++ b/geode-web-api/build.gradle
@@ -60,6 +60,7 @@ dependencies {
 
   provided 'javax.servlet:javax.servlet-api:' + project.'javax.servlet-api.version'
   provided project(':geode-core')
+  provided project(':geode-lucene')
 }
 
 war {
diff --git a/geode-web-api/src/main/java/org/apache/geode/rest/internal/web/controllers/FunctionAccessController.java b/geode-web-api/src/main/java/org/apache/geode/rest/internal/web/controllers/FunctionAccessController.java
index edfdeaa42..277ced77a 100644
--- a/geode-web-api/src/main/java/org/apache/geode/rest/internal/web/controllers/FunctionAccessController.java
+++ b/geode-web-api/src/main/java/org/apache/geode/rest/internal/web/controllers/FunctionAccessController.java
@@ -193,14 +193,18 @@ public class FunctionAccessController extends AbstractBaseController {
 
     try {
       if (argsInBody != null) {
-        Object[] args = jsonToObjectArray(argsInBody);
-
-        // execute function with specified arguments
-        if (args.length == 1) {
-          results = function.setArguments(args[0]).execute(functionId);
-        } else {
-          results = function.setArguments(args).execute(functionId);
-        }
+        System.out.println("GGG:"+argsInBody+":"+functionId);
+        results = function.setArguments(argsInBody).execute(functionId);
+//        Object[] args = jsonToObjectArray(argsInBody);
+//
+//        // execute function with specified arguments
+//        if (args.length == 1) {
+//          System.out.println("GGG:"+args[0]+":"+functionId);
+//          results = function.setArguments(args[0]).execute(functionId);
+//        } else {
+//          System.out.println("GGG2:"+args+":"+functionId);
+//          results = function.setArguments(args).execute(functionId);
+//        }
       } else {
         // execute function with no args
         results = function.execute(functionId);
diff --git a/geode-web-api/src/main/java/org/apache/geode/rest/internal/web/controllers/PdxBasedCrudController.java b/geode-web-api/src/main/java/org/apache/geode/rest/internal/web/controllers/PdxBasedCrudController.java
index 3dd987ff9..3dd85b12d 100644
--- a/geode-web-api/src/main/java/org/apache/geode/rest/internal/web/controllers/PdxBasedCrudController.java
+++ b/geode-web-api/src/main/java/org/apache/geode/rest/internal/web/controllers/PdxBasedCrudController.java
@@ -18,6 +18,13 @@ import io.swagger.annotations.Api;
 import io.swagger.annotations.ApiOperation;
 import io.swagger.annotations.ApiResponse;
 import io.swagger.annotations.ApiResponses;
+
+import org.apache.geode.cache.lucene.LuceneQuery;
+import org.apache.geode.cache.lucene.LuceneQueryException;
+import org.apache.geode.cache.lucene.LuceneServiceProvider;
+import org.apache.geode.cache.lucene.PageableLuceneQueryResults;
+import org.apache.geode.cache.lucene.internal.LuceneIndexImpl;
+import org.apache.geode.cache.lucene.internal.LuceneServiceImpl;
 import org.apache.geode.internal.logging.LogService;
 import org.apache.geode.rest.internal.web.controllers.support.JSONTypes;
 import org.apache.geode.rest.internal.web.controllers.support.RegionData;
@@ -191,6 +198,79 @@ public class PdxBasedCrudController extends CommonCrudController {
   }
 
   /**
+   * Do lucene query in a given Region
+   * 
+   * @param region gemfire region name
+   * @param index gemfire lucene index name
+   * @param query lucene query string
+   * @return JSON document
+   */
+  @RequestMapping(method = RequestMethod.GET, value = "/{region}/lucene query",
+      produces = MediaType.APPLICATION_JSON_UTF8_VALUE)
+  @ApiOperation(value = "lucene query on region",
+      notes = "Do lucene query on a region.",
+      response = void.class)
+  @ApiResponses({@ApiResponse(code = 200, message = "OK."),
+      @ApiResponse(code = 400, message = "Bad request."),
+      @ApiResponse(code = 401, message = "Invalid Username or Password."),
+      @ApiResponse(code = 403, message = "Insufficient privileges for operation."),
+      @ApiResponse(code = 404, message = "Region does not exist."),
+      @ApiResponse(code = 500, message = "GemFire throws an error or exception.")})
+  @PreAuthorize("@securityService.authorize('DATA', 'WRITE', #region)")
+  public ResponseEntity<?> read(@PathVariable("region") String region,
+      @RequestParam(value = "index",
+      defaultValue = "") final String index,
+//      @RequestParam("index") String index,
+      @RequestParam(value = "query",
+          defaultValue = "name:Tom99*") final String query) {
+    logger.debug("Do lucene query in Region ({})...", region);
+
+    region = decode(region);
+//    index = decode(index);
+//    query = decode(query);
+
+    Map<Object, Object> valueObjs = null;
+    final RegionData<Object> data = new RegionData<>(region);
+
+    final HttpHeaders headers = new HttpHeaders();
+    String keyList = null;
+    int regionSize = getRegion(region).size();
+    List<Object> keys = new ArrayList<>(regionSize);
+    List<Object> values = new ArrayList<>(regionSize);
+
+    LuceneServiceImpl service = (LuceneServiceImpl) LuceneServiceProvider.get(getCache());
+    LuceneIndexImpl luceneIndex = (LuceneIndexImpl)service.getIndex(index, region);
+    LuceneQuery luceneQuery = service.createLuceneQueryFactory().create(index, region, query, "name");
+    
+    try {
+      PageableLuceneQueryResults<Object, Object> results = luceneQuery.findPages();
+      while(results.hasNext()) {
+        results.next().stream().forEach(struct -> {
+          Object value = struct.getValue();
+          values.add(value);
+          Object key = struct.getKey();
+          keys.add(key);
+        });
+      }
+    }
+    catch (LuceneQueryException e) {
+    }
+    data.add(values);
+    keyList = StringUtils.collectionToDelimitedString(keys, ",");
+    
+    for (Map.Entry<Object, Object> entry : getValues(region).entrySet()) {
+      Object value = entry.getValue();
+      if (value != null) {
+        keys.add(entry.getKey());
+        values.add(value);
+      }
+    }
+    
+    headers.set("Content-Location", toUri(region, keyList).toASCIIString());
+    return new ResponseEntity<RegionData<?>>(data, headers, HttpStatus.OK);
+  }
+  
+  /**
    * Reading data for set of keys
    * 
    * @param region gemfire region name

diff --git a/geode-assembly/build.gradle b/geode-assembly/build.gradle
index 19a73f324..b39f7e6df 100755
--- a/geode-assembly/build.gradle
+++ b/geode-assembly/build.gradle
@@ -194,6 +194,8 @@ def cp = {
         it.contains('lucene-analyzers-common') ||
         it.contains('lucene-core') ||
         it.contains('lucene-queries') ||
+        it.contains('lucene-join') ||
+        it.contains('lucene-grouping') ||
         it.contains('lucene-queryparser') ||
 
         // dependencies from geode-protobuf
diff --git a/geode-assembly/src/test/resources/expected_jars.txt b/geode-assembly/src/test/resources/expected_jars.txt
index 05f583459..fc18ab4ad 100644
--- a/geode-assembly/src/test/resources/expected_jars.txt
+++ b/geode-assembly/src/test/resources/expected_jars.txt
@@ -46,6 +46,8 @@ lucene-analyzers-common
 lucene-core
 lucene-queries
 lucene-queryparser
+lucene-join
+lucene-grouping
 mx4j
 mx4j-remote
 mx4j-tools
diff --git a/geode-lucene/build.gradle b/geode-lucene/build.gradle
index 74de7a6a8..360ab55fb 100644
--- a/geode-lucene/build.gradle
+++ b/geode-lucene/build.gradle
@@ -22,6 +22,8 @@ dependencies {
     compile 'org.apache.lucene:lucene-analyzers-common:' + project.'lucene.version'
     compile 'org.apache.lucene:lucene-core:' + project.'lucene.version'
     compile 'org.apache.lucene:lucene-queries:' + project.'lucene.version'
+    compile 'org.apache.lucene:lucene-join:' + project.'lucene.version'
+    compile 'org.apache.lucene:lucene-grouping:' + project.'lucene.version'
     compile ('org.apache.lucene:lucene-queryparser:' + project.'lucene.version') {
       exclude module: 'lucene-sandbox'
     }
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/IndexRepositoryImpl.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/IndexRepositoryImpl.java
index f356bef6b..597473aed 100644
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/IndexRepositoryImpl.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/IndexRepositoryImpl.java
@@ -15,6 +15,7 @@
 
 package org.apache.geode.cache.lucene.internal.repository;
 
+import org.apache.commons.beanutils.PropertyUtils;
 import org.apache.geode.cache.Region;
 import org.apache.geode.cache.lucene.internal.LuceneIndexStats;
 import org.apache.geode.cache.lucene.internal.repository.serializer.LuceneSerializer;
@@ -33,7 +34,10 @@ import org.apache.lucene.store.AlreadyClosedException;
 import org.apache.geode.distributed.LockNotHeldException;
 
 import java.io.IOException;
+import java.util.ArrayList;
 import java.util.function.IntSupplier;
+import java.lang.reflect.Field;
+import java.lang.reflect.InvocationTargetException;
 
 /**
  * A repository that writes to a single lucene index writer
@@ -95,10 +99,22 @@ public class IndexRepositoryImpl implements IndexRepository {
   public void update(Object key, Object value) throws IOException {
     long start = stats.startUpdate();
     try {
-      Document doc = new Document();
-      SerializerUtil.addKey(key, doc);
-      serializer.toDocument(value, doc);
-      writer.updateDocument(SerializerUtil.getKeyTerm(doc), doc);
+//      Document doc = new Document();
+//      SerializerUtil.addKey(key, doc);
+//      serializer.toDocument(value, doc);
+//      writer.updateDocument(SerializerUtil.getKeyTerm(doc), doc);
+      ArrayList<Document> documents = (ArrayList<Document>)serializer.toDocuments(value);
+      if (documents == null) {
+        // PDX
+        return;
+      }
+      for (Document doc:documents) {
+        SerializerUtil.addKey(key, doc);
+      }
+      Document lastDoc = documents.get(documents.size()-1);
+//      SerializerUtil.addKey(key, lastDoc);
+//      System.out.println("GGG:"+documents);
+      writer.updateDocuments(SerializerUtil.getKeyTerm(lastDoc), documents);
     } finally {
       stats.endUpdate(start);
     }
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/HeterogeneousLuceneSerializer.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/HeterogeneousLuceneSerializer.java
index b0a98a1e8..889e3f7c2 100644
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/HeterogeneousLuceneSerializer.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/HeterogeneousLuceneSerializer.java
@@ -14,8 +14,14 @@
  */
 package org.apache.geode.cache.lucene.internal.repository.serializer;
 
+import java.lang.reflect.Field;
+import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collection;
+import java.util.HashMap;
+import java.util.HashSet;
 import java.util.Map;
+import java.util.Set;
 
 import org.apache.logging.log4j.Logger;
 import org.apache.lucene.document.Document;
@@ -46,7 +52,7 @@ public class HeterogeneousLuceneSerializer implements LuceneSerializer {
    * 
    * Weak so that entry will be removed if a class is garbage collected.
    */
-  private Map<Class<?>, LuceneSerializer> mappers =
+  public Map<Class<?>, LuceneSerializer> mappers =
       new CopyOnWriteWeakHashMap<Class<?>, LuceneSerializer>();
 
   private static final Logger logger = LogService.getLogger();
@@ -86,22 +92,103 @@ public class HeterogeneousLuceneSerializer implements LuceneSerializer {
     }
   }
 
+  public HashMap<Class<?>, HashSet<String>> definedFieldsForEachNestedClass = new HashMap();
+
+  private void preProcessingForNestObjects(Object value, String[] fields) {
+    Class<?> clazz = value.getClass();
+    HashSet<String> definedFieldNamesForParent = definedFieldsForEachNestedClass.get(clazz);
+    if (definedFieldNamesForParent == null) {
+      definedFieldNamesForParent = new HashSet<String>();
+      definedFieldsForEachNestedClass.put(clazz, definedFieldNamesForParent);
+    }
+
+    HashMap<String, HashSet<String>> parentChildFieldMapping =  new HashMap();
+    for (String f:fields) {
+      int firstDot = f.indexOf(".");
+      if (firstDot != -1) {
+        String parentFieldName = f.substring(0, firstDot);
+        String childFieldName = f.substring(firstDot+1);
+        HashSet<String> childFieldSet = parentChildFieldMapping.get(parentFieldName);
+        if (childFieldSet == null) {
+          childFieldSet = new HashSet<String>();
+          parentChildFieldMapping.put(parentFieldName, childFieldSet);
+        }
+        childFieldSet.add(childFieldName);
+
+        definedFieldNamesForParent.add(parentFieldName);
+      } else {
+        definedFieldNamesForParent.add(f);
+      }
+    }
+
+    for (Map.Entry<String, HashSet<String>> entry:parentChildFieldMapping.entrySet()) {
+      try {
+        String parentFieldName = entry.getKey();
+        HashSet<String> childFieldSet = entry.getValue();
+        String[] childFields = new String[childFieldSet.size()];
+        childFieldSet.toArray(childFields);
+        checkOneNestedField(value, parentFieldName, childFields);
+      }
+      catch (Exception e) {
+        e.printStackTrace();
+      }
+    }
+  }
+
+  private void checkOneNestedField(Object parentValue, String parentField, String[] childFields) throws IllegalArgumentException, IllegalAccessException, NoSuchFieldException, SecurityException {
+    // now check if there's grandchild in nestedFields
+    Class<?> parentClazz = parentValue.getClass();
+    Field field = parentClazz.getDeclaredField(parentField);
+    Object childValue = null;
+    try {
+      field.setAccessible(true);
+      childValue = field.get(parentValue);
+    } catch (Exception e) {
+      e.printStackTrace(System.out);
+    }
+    preProcessingForNestObjects(childValue, childFields);
+  }
+
   /**
    * Get the field mapper based on the type of the given object.
    */
-  private LuceneSerializer getFieldMapper(Object value) {
+  public LuceneSerializer getFieldMapper(Object value) {
     if (value instanceof PdxInstance) {
       return pdxMapper;
     } else {
-      Class<?> clazz = value.getClass();
-      LuceneSerializer mapper = mappers.get(clazz);
+//      Class<?> clazz = value.getClass();
+      LuceneSerializer mapper = mappers.get(value.getClass());
       if (mapper == null) {
-        mapper = new ReflectionLuceneSerializer(clazz, indexedFields);
-        mappers.put(clazz, mapper);
+        // only do pre-processing when mapper==null
+        // it will find all the nested classes for the index
+        preProcessingForNestObjects(value, indexedFields);
+        for (Map.Entry<Class<?>, HashSet<String>> entry:definedFieldsForEachNestedClass.entrySet()) {
+          Class<?> clazz = entry.getKey();
+          if (mappers.get(clazz) == null) {
+            HashSet<String> childFieldSet = entry.getValue();
+            String[] fields = entry.getValue().toArray(new String[childFieldSet.size()]);
+            mapper = new ReflectionLuceneSerializer(clazz, fields, this);
+            mappers.put(clazz, mapper);
+          }
+        }
       }
-      return mapper;
+
+      return mappers.get(value.getClass());
     }
   }
 
+  @Override
+  public Collection<Document> toDocuments(Object value) {
+    if (value == null) {
+      return null;
+    }
 
+    LuceneSerializer mapper = getFieldMapper(value);
+
+    Collection<Document> docs = mapper.toDocuments(value);
+    if (logger.isDebugEnabled()) {
+      logger.debug("HeterogeneousLuceneSerializer.toDocuments:" + docs);
+    }
+    return docs;
+  }
 }
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/LuceneSerializer.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/LuceneSerializer.java
index fa38f4730..1c929783d 100644
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/LuceneSerializer.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/LuceneSerializer.java
@@ -15,6 +15,8 @@
 
 package org.apache.geode.cache.lucene.internal.repository.serializer;
 
+import java.util.Collection;
+
 import org.apache.lucene.document.Document;
 
 /**
@@ -27,4 +29,6 @@ public interface LuceneSerializer {
    */
   void toDocument(Object value, Document doc);
 
+  //Proposed method
+  Collection<Document> toDocuments(Object value);
 }
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PdxLuceneSerializer.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PdxLuceneSerializer.java
index f34390c65..994f00c25 100644
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PdxLuceneSerializer.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PdxLuceneSerializer.java
@@ -18,6 +18,7 @@ package org.apache.geode.cache.lucene.internal.repository.serializer;
 import org.apache.logging.log4j.Logger;
 import org.apache.lucene.document.Document;
 
+import java.util.Collection;
 import org.apache.geode.internal.logging.LogService;
 import org.apache.geode.pdx.PdxInstance;
 
@@ -50,4 +51,10 @@ class PdxLuceneSerializer implements LuceneSerializer {
       logger.debug("PdxLuceneSerializer.toDocument:" + doc);
     }
   }
+
+  @Override
+  public Collection<Document> toDocuments(Object value) {
+    // TODO Auto-generated method stub
+    return null;
+  }
 }
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PrimitiveSerializer.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PrimitiveSerializer.java
index cf644a8bc..a47c69624 100644
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PrimitiveSerializer.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/PrimitiveSerializer.java
@@ -14,6 +14,7 @@
  */
 package org.apache.geode.cache.lucene.internal.repository.serializer;
 
+import java.util.Collection;
 import org.apache.geode.cache.lucene.LuceneService;
 
 import org.apache.lucene.document.Document;
@@ -28,4 +29,10 @@ public class PrimitiveSerializer implements LuceneSerializer {
   public void toDocument(final Object value, final Document doc) {
     SerializerUtil.addField(doc, LuceneService.REGION_VALUE_FIELD, value);
   }
+
+  @Override
+  public Collection<Document> toDocuments(Object value) {
+    // TODO Auto-generated method stub
+    return null;
+  }
 }
diff --git a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionLuceneSerializer.java b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionLuceneSerializer.java
index 07a66fb0a..5ab95a371 100644
--- a/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionLuceneSerializer.java
+++ b/geode-lucene/src/main/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionLuceneSerializer.java
@@ -18,7 +18,10 @@ package org.apache.geode.cache.lucene.internal.repository.serializer;
 import java.lang.reflect.Field;
 import java.util.ArrayList;
 import java.util.Arrays;
+import java.util.Collection;
+import java.util.HashMap;
 import java.util.HashSet;
+import java.util.Map;
 import java.util.Set;
 
 import org.apache.logging.log4j.Logger;
@@ -33,10 +36,12 @@ import org.apache.geode.internal.logging.LogService;
 class ReflectionLuceneSerializer implements LuceneSerializer {
 
   private Field[] fields;
+  HeterogeneousLuceneSerializer hSerializer;
 
   private static final Logger logger = LogService.getLogger();
 
-  public ReflectionLuceneSerializer(Class<? extends Object> clazz, String[] indexedFields) {
+  public ReflectionLuceneSerializer(Class<? extends Object> clazz, String[] indexedFields, HeterogeneousLuceneSerializer hSerializer) {
+    this.hSerializer = hSerializer;
     Set<String> fieldSet = new HashSet<String>();
     fieldSet.addAll(Arrays.asList(indexedFields));
 
@@ -47,7 +52,7 @@ class ReflectionLuceneSerializer implements LuceneSerializer {
     while (clazz != Object.class) {
       for (Field field : clazz.getDeclaredFields()) {
         Class<?> type = field.getType();
-        if (fieldSet.contains(field.getName()) && SerializerUtil.isSupported(type)) {
+        if (fieldSet.contains(field.getName())) {
           field.setAccessible(true);
           foundFields.add(field);
         }
@@ -57,6 +62,7 @@ class ReflectionLuceneSerializer implements LuceneSerializer {
     }
 
     this.fields = foundFields.toArray(new Field[foundFields.size()]);
+    this.hSerializer = hSerializer;
   }
 
   @Override
@@ -76,4 +82,39 @@ class ReflectionLuceneSerializer implements LuceneSerializer {
       logger.debug("ReflectionLuceneSerializer.toDocument:" + doc);
     }
   }
+
+  @Override
+  public Collection<Document> toDocuments(Object value) {
+    ArrayList<Document> docs = new ArrayList();
+    Document parentDoc = new Document();
+    boolean isParentDocEmpty = true;
+
+    for (Field field : fields) {
+      try {
+        field.setAccessible(true);
+        Object fieldValue = field.get(value);
+        Class<?> fieldType = field.getType();
+        if (fieldValue == null) {
+          continue;
+        }
+
+        if (hSerializer.definedFieldsForEachNestedClass.containsKey(fieldType)) {
+          LuceneSerializer childSerializer = hSerializer.getFieldMapper(fieldValue);
+          docs.addAll(childSerializer.toDocuments(fieldValue));
+        } else {
+          SerializerUtil.addField(parentDoc, field.getName(), fieldValue);
+          isParentDocEmpty = false;
+        }
+      } catch (IllegalArgumentException | IllegalAccessException e) {
+        // TODO - what to do if we can't read a field?
+      }
+    }
+    if (logger.isDebugEnabled()) {
+      logger.debug("ReflectionLuceneSerializer.toDocuments:" + docs);
+    }
+    if (!isParentDocEmpty) {
+      docs.add(parentDoc);
+    }
+    return docs;
+  }
 }
diff --git a/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionFieldMapperJUnitTest.java b/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionFieldMapperJUnitTest.java
index 3e0fe3ff8..e7aad0c5d 100644
--- a/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionFieldMapperJUnitTest.java
+++ b/geode-lucene/src/test/java/org/apache/geode/cache/lucene/internal/repository/serializer/ReflectionFieldMapperJUnitTest.java
@@ -32,8 +32,8 @@ public class ReflectionFieldMapperJUnitTest {
   public void testAllFields() {
 
     String[] allFields = new String[] {"s", "i", "l", "d", "f", "s2"};
-    ReflectionLuceneSerializer mapper1 = new ReflectionLuceneSerializer(Type1.class, allFields);
-    ReflectionLuceneSerializer mapper2 = new ReflectionLuceneSerializer(Type2.class, allFields);
+    ReflectionLuceneSerializer mapper1 = new ReflectionLuceneSerializer(Type1.class, allFields, null);
+    ReflectionLuceneSerializer mapper2 = new ReflectionLuceneSerializer(Type2.class, allFields, null);
 
     Type1 t1 = new Type1("a", 1, 2L, 3.0, 4.0f);
     Type2 t2 = new Type2("a", 1, 2L, 3.0, 4.0f, "b");
@@ -64,7 +64,7 @@ public class ReflectionFieldMapperJUnitTest {
   public void testIgnoreInvalid() {
 
     String[] fields = new String[] {"s", "o", "s2"};
-    ReflectionLuceneSerializer mapper = new ReflectionLuceneSerializer(Type2.class, fields);
+    ReflectionLuceneSerializer mapper = new ReflectionLuceneSerializer(Type2.class, fields, null);
 
     Type2 t = new Type2("a", 1, 2L, 3.0, 4.0f, "b");
 
@@ -80,7 +80,7 @@ public class ReflectionFieldMapperJUnitTest {
   public void testNullField() {
 
     String[] fields = new String[] {"s", "o", "s2"};
-    ReflectionLuceneSerializer mapper = new ReflectionLuceneSerializer(Type2.class, fields);
+    ReflectionLuceneSerializer mapper = new ReflectionLuceneSerializer(Type2.class, fields, null);
 
     Type2 t = new Type2("a", 1, 2L, 3.0, 4.0f, null);
 
